{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elenasofia98/PracticalNLP-2023-2024/blob/main/HoL05_1_ParaphraseClassification_LexicalFeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbFlhgfVGtY3",
        "outputId": "57762016-d5b6-447f-b4de-6ff2e4009b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stanza in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from stanza) (2.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.31.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza) (3.2.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from stanza) (0.10.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXxeSPvSMqL2"
      },
      "source": [
        "# Recognizing Paraphrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "3902e0a182f34b1d89dc789d6cf35494",
            "5d5a5ed8bd4e46caa18682ea63eb86bc",
            "634052a393ef4e9395986daeb365a1c8",
            "f156f93c71454009be44f43dc4769aa5",
            "427f2c4c077c4147a0e96cff3d702155",
            "6ec7f972593e47cabf4b84e94277384f",
            "12bed84d704a47ce84d648c89d9b4305",
            "ce182cc2bdeb45e78a083326ce90856f",
            "855a54b30b414e3d9d828e0f5338582c",
            "1f975a4a6a5e46b3b7af3cedce22fb85",
            "959b7696f6774e46b05bf6a4dfd2d33b"
          ]
        },
        "id": "zycJuNDPn6WR",
        "outputId": "b7d988ef-8c3e-4b4c-e415-b3b2d2c0eee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.7.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3902e0a182f34b1d89dc789d6cf35494"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:stanza:Language en package default expects mwt, which has been added\n",
            "INFO:stanza:Loading these models for language: en (English):\n",
            "=================================\n",
            "| Processor | Package           |\n",
            "---------------------------------\n",
            "| tokenize  | combined          |\n",
            "| mwt       | combined          |\n",
            "| pos       | combined_charlm   |\n",
            "| lemma     | combined_nocharlm |\n",
            "| depparse  | combined_charlm   |\n",
            "=================================\n",
            "\n",
            "INFO:stanza:Using device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: mwt\n",
            "INFO:stanza:Loading: pos\n",
            "INFO:stanza:Loading: lemma\n",
            "INFO:stanza:Loading: depparse\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        }
      ],
      "source": [
        "import stanza\n",
        "nlp = stanza.Pipeline('en', processors='tokenize,lemma,pos,depparse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYOdV3dxNycu"
      },
      "source": [
        "# MRPC (Microsoft Research Paraphrase Corpus)\n",
        "Introduced by William B. Dolan et al. in Automatically Constructing a Corpus of Sentential Paraphrases\n",
        "Microsoft Research Paraphrase Corpus (MRPC) is a corpus consists of 5,801 sentence pairs collected from newswire articles. Each pair is labelled if it is a paraphrase or not by human annotators. The whole set is divided into a training subset (4,076 sentence pairs of which 2,753 are paraphrases) and a test subset (1,725 pairs of which 1,147 are paraphrases)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rz6Q8IshwRA",
        "outputId": "d9b1f1b0-e271-4df3-8792-5185c935679e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f78af7a52f5347a6b15ceabb4d57a519",
            "b4a663d0a4b34f9b9173bfe58397d5b1",
            "26e79a77e88c4a1c8a1b1352908e9f74",
            "b397e0a871e54c85921a5c93fe16aa7c",
            "bedd51e2ed524f5fad8fd747682613c5",
            "d31fd54f8733440aaab0cc751de96c34",
            "ab3282e9c1854e73ae818bbd169ddf33",
            "a0c137bae7b64c68996f239ecd86a7ac",
            "479ad2b4ce044a7da9e91d33952abf25",
            "6f3ed4402e164550aafeacfb4241a176",
            "9c216a48cbdc432fa9b113c3e4a4691e"
          ]
        },
        "id": "34Y0vJ8zI1Wv",
        "outputId": "c44afd72-7165-4be8-cf65-be729616a92a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1467 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f78af7a52f5347a6b15ceabb4d57a519"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from ast import literal_eval\n",
        "from datasets import Dataset, DatasetDict\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "def parse(example, nlp):\n",
        "    parsed_example = {}\n",
        "    for i in [1,2]:\n",
        "        parsed_sent = nlp(example[f'sentence{i}'])\n",
        "        for feature in [k+str(i) for k in ['words', 'deprel', 'heads', 'headsidx', 'pos']]:\n",
        "            parsed_example[feature] = []\n",
        "\n",
        "        for sent in parsed_sent.sentences:\n",
        "            for word in sent.words:\n",
        "                parsed_example[f'words{i}'].append(word.text)\n",
        "\n",
        "                parsed_example[f'deprel{i}'].append(word.deprel)\n",
        "\n",
        "                head_idx = word.head-1\n",
        "                parsed_example[f\"headsidx{i}\"].append(head_idx)\n",
        "\n",
        "                head = sent.words[head_idx].text if head_idx > 0 else \"root\"\n",
        "                parsed_example[f\"heads{i}\"].append(head)\n",
        "\n",
        "                parsed_example[f\"pos{i}\"].append(word.upos)\n",
        "    return parsed_example\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if not os.path.exists('train.json') or not os.path.exists('validation.json'):\n",
        "    dataset = load_dataset(\"glue\", \"mrpc\",  split={\"train\":'train[:40%]','validation':'validation[:50%]'})\n",
        "    for split in ['train', 'validation']:\n",
        "        dataset[split] = dataset[split].map(lambda x: parse(x, nlp=nlp), batched=False)\n",
        "        dataset[split].to_pandas().to_json(f'{split}.json')\n",
        "else:\n",
        "\n",
        "    tds = Dataset.from_pandas(pd.read_json('train.json'))\n",
        "    vds = Dataset.from_pandas(pd.read_json('validation.json'))\n",
        "\n",
        "    dataset = DatasetDict()\n",
        "\n",
        "    dataset['train'] = tds\n",
        "    dataset['validation'] = vds\n",
        "\n",
        "\n",
        "\n",
        "display(dataset)\n",
        "display(dataset['train'][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset['train']), len(dataset['validation'])"
      ],
      "metadata": {
        "id": "VXmv3iFvWC8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxikX6mFQaBz"
      },
      "source": [
        "https://aclanthology.org/U06-1019.pdf\n",
        "## Using Dependency-Based Features to Take the “Para-farce” out of Paraphrase\n",
        "\n",
        "\"We propose that an automatic classifier be employed to identify and filter out inconsistent novel\n",
        "sentences. To do so, we couch Paraphrase Classification as a supervised machine learning task and\n",
        "train a classifier on the Microsoft Research Paraphrase (MSR) Corpus (Dolan et al., 2004), a corpus specifically collected for this task. In particular, we are especially interested in exploring the\n",
        "use of syntactic dependency information in making this classification.\n",
        "[...]\n",
        "In this paper, we decided to explore features encoding information about the relative difference\n",
        "between the structures of the two sentence.\n",
        "We\n",
        "thus experimented with a range of features ranging\n",
        "from differences in sentence length, to word overlap, to syntax dependency tree overlap, where the\n",
        "latter approximately represent predicate and argument structure.\n",
        "\n",
        "1. **unigram recall**\n",
        "2. **unigram precision**\n",
        "3. lemmatised unigram precision\n",
        "4. lemmatised unigram recall\n",
        "5. Bleu precision\n",
        "6. Bleu recall\n",
        "7. lemmatised Bleu precision\n",
        "8. lemmatised Bleu recall\n",
        "9. fmeasure\n",
        "10. **dependency relation precision**\n",
        "11. **dependency relation recall**\n",
        "12. lemmatised dependency relation precision\n",
        "13. lemmatised dependency relation recall\n",
        "14. **tree-edit distance (Zhang and Sasha algorithm)**\n",
        "15. lemmatised tree-edit distance (Zhang and Sasha algorithm)\n",
        "16. difference in sentence length (in words)\n",
        "17. absolute difference in sentence length (in words)\n",
        "\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v2VmLlwUT_k"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "TRAIN = 'train'\n",
        "TEST = 'validation'\n",
        "\n",
        "splits = [TRAIN, TEST]\n",
        "X = {split: pd.DataFrame([]) for split in splits}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcVzU-ymWVDK"
      },
      "outputs": [],
      "source": [
        "def overlap(s1, s2):\n",
        "    s1 = set(s1)\n",
        "    s2 = set(s2)\n",
        "\n",
        "    return len(s1.intersection(s2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lexical features"
      ],
      "metadata": {
        "id": "0mHSQRm1NYIb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e73UxUVRUil4"
      },
      "outputs": [],
      "source": [
        "# precision = word-overlap(sentence1,sentence2)/word-count(sentence1)\n",
        "# recall = word-overlap(sentence1,sentence2)/word-count(sentence2)\n",
        "\n",
        "for split in splits:\n",
        "    X[split]['precision']   = [overlap(example['words1'], example['words2'])/len(set(example['words1'])) for example in dataset[split]]\n",
        "    X[split]['recall']      = [overlap(example['words2'], example['words1'])/len(set(example['words2'])) for example in dataset[split]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4K4Jo8wzYSYq"
      },
      "outputs": [],
      "source": [
        "# A relation is simply a pair of words in a parent-child relationship within the dependency tree, refered to as head-modifier relationships.\n",
        "# In this paper, we ignored the label of the relationships which indicates the semantic role.\n",
        "# The next series of features examines the use of features based on an overlap of such head-modifier relations (hereafter, relations) between sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dependency overlap"
      ],
      "metadata": {
        "id": "LIzic0LwNdGT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgMJTPdBYuNC"
      },
      "outputs": [],
      "source": [
        "# Feature 10 is the precision score calculated from the overlap according to the following formula:\n",
        "# precisiond (dependency precision) = |relations(sentence1) ∩ relations(sentence2)|/|relations(sentence1)|\n",
        "# where relations(sentence_i) is the set of headmodifier relations for some sentence.\n",
        "\n",
        "def relations(example, sentence_index):\n",
        "    rels = []\n",
        "    for i in range(len(example[f\"words{sentence_index}\"])):\n",
        "        rels.append((example[f\"words{sentence_index}\"][i],example[f\"heads{sentence_index}\"][i]))\n",
        "    return rels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Krlk71bnbCZh"
      },
      "outputs": [],
      "source": [
        "for split in splits:\n",
        "    precisiond = []\n",
        "    recalld = []\n",
        "    for example in dataset[split]:\n",
        "        relations1 = relations(example, 1)\n",
        "        relations2 = relations(example, 2)\n",
        "\n",
        "        precisiond.append(overlap(relations1, relations2)/len(set(relations1)))\n",
        "        recalld.append(overlap(relations2, relations1)/len(set(relations2)))\n",
        "    X[split]['precisiond'] = precisiond\n",
        "    X[split]['recalld'] = recalld"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tree edit distance"
      ],
      "metadata": {
        "id": "MsNaVYcZNuNR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4K0JblXf8Cx"
      },
      "outputs": [],
      "source": [
        "# Including tree edit\n",
        "# As another measure of how alike or different the two sentences are from each other,\n",
        "# we decided to examine how similar their respective dependency trees were.\n",
        "# Ordered tree-edit distance algorithms\n",
        "# are designed to find the least costly set of operations that will transform one tree into another.\n",
        "# In our case, we want to find the cost of transforming\n",
        "# dependency parse trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z_kTX6al4qm"
      },
      "outputs": [],
      "source": [
        "# Our implementation is based on the dynamic\n",
        "# programming algorithm of Zhang and Shasha (1989).\n",
        "# The algorithm finds the optimum (cheapest) set of tree-edit operations in polynomial time.\n",
        "# This algorithm has been used in the past in\n",
        "# Question-Answering as a means of scoring similarity between questions an candidate answers\n",
        "! pip install zss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHhmfju8xmej"
      },
      "outputs": [],
      "source": [
        "from zss import simple_distance, Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQqD6vKIxoUy"
      },
      "outputs": [],
      "source": [
        "def get_dtree(example, sentence_index):\n",
        "    dtree = {}\n",
        "    for i in range(len(example[f'words{sentence_index}'])):\n",
        "\n",
        "        head = example[f'heads{sentence_index}'][i]\n",
        "        head_idx = example[f'headsidx{sentence_index}'][i]\n",
        "        if f\"{head}_{head_idx}\" not in dtree:\n",
        "            dtree[f\"{head}_{head_idx}\"] = []\n",
        "\n",
        "        dtree[f\"{head}_{head_idx}\"].append(f\"{example[f'words{sentence_index}'][i]}_{i}\")\n",
        "    return dtree\n",
        "\n",
        "def construct_tree(root, dtree):\n",
        "    tree = Node(root)\n",
        "\n",
        "    # is leaf\n",
        "    if root not in dtree:\n",
        "        return tree\n",
        "\n",
        "    # has children\n",
        "    children = dtree[root]\n",
        "    for child in children:\n",
        "        subtree = construct_tree(root=child, dtree=dtree) # recursevely, build the subtree rooted in each children\n",
        "        tree = tree.addkid(subtree)\n",
        "\n",
        "    return tree"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We calculated the tree-edit distance over the syntactic dependency parse trees.\n",
        "# Inserting, deleting and renaming nodes, or words,\n",
        "# into a dependency tree, were all given an equal cost.\n",
        "# The cost returned by the algorithm is simply the\n",
        "# sum of all operations required to transform one\n",
        "# tree into the other. This cost was normalised by\n",
        "# the number nodes in the target dependency tree to\n",
        "# produce a value between 0 and 1"
      ],
      "metadata": {
        "id": "XXGrHHWsJhKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "RnXI5iEVVb6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root='root_-1'\n",
        "for split in splits:\n",
        "    ted = []\n",
        "    for example in tqdm(dataset[split]):\n",
        "        tree1 = construct_tree(root=root, dtree=get_dtree(example, sentence_index=1))\n",
        "        tree2 = construct_tree(root=root, dtree=get_dtree(example, sentence_index=2))\n",
        "\n",
        "        ted.append(simple_distance(tree1, tree2)/len(example['words2']))\n",
        "\n",
        "    X[split]['ted'] = ted"
      ],
      "metadata": {
        "id": "kMbZCR--MAgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classifier"
      ],
      "metadata": {
        "id": "JGOdTwXHNTn4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUpUle8wc-7t"
      },
      "outputs": [],
      "source": [
        "for split in splits:\n",
        "    X[split]['target'] = [example['label'] for example in dataset[split]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHZ8QlRUdyMu"
      },
      "outputs": [],
      "source": [
        "X[TRAIN]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6wZBDkhd2Zs"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "# Classifier - Algorithm - SVM\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=1.0, kernel='poly', degree=3)\n",
        "\n",
        "\n",
        "X_train = X[TRAIN][[feature for feature in X[TRAIN].columns if feature!='target']]\n",
        "y_train = X[TRAIN]['target']\n",
        "\n",
        "\n",
        "SVM.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8563Z8XeUvq"
      },
      "outputs": [],
      "source": [
        "pred_train = SVM.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Dgqgqx1eaE3"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_train, pred_train)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=SVM.classes_)\n",
        "\n",
        "disp.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHNy0pa6eldD"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_pred=pred_train, y_true=y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8ZSbOw-fdMz"
      },
      "outputs": [],
      "source": [
        "X_test = X[TEST][[feature for feature in X[TEST].columns if feature!='target']]\n",
        "y_test = X[TEST]['target']\n",
        "\n",
        "pred_test = SVM.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D084rpsmfnqv"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, pred_test)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=SVM.classes_)\n",
        "\n",
        "disp.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLf-BFH2fti7"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_pred=pred_test, y_true=y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lexical Models\n",
        "SOL 1) Lets analyze words:\n",
        "- Bag of Words (BOW) with One Hot Encoding for words, only for content words\n",
        "\n",
        "SOL 2) map each word to its \"meaning\". Synset for each word? Nope, for content words\n",
        "- Bag of Synsets: for each content word, the synsets for that words\n",
        "\n",
        "SOL 2.5) Paraphrases share a common lexicon\n",
        "- Words that appear in a sentence and do/do not appear in the other, \"subtraction\" of words\n",
        "\n",
        "SOL 3) map each word to its \"meaning\", hand crafcted features\n",
        "- Words with the same syntactic role does have the same synset\n",
        "- Do predicates have the same synset? Is their meaning at least similar?\n",
        "- **Having the same syntactic role** for example subjs and objs, compute cross similarities\n"
      ],
      "metadata": {
        "id": "vN3Pxym25A_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BOW"
      ],
      "metadata": {
        "id": "66y9FYcuNyBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = set([token for i in range(len(dataset['train']))\n",
        "            for token in dataset['train'][i]['words1'] + dataset['train'][i]['words2']])\n",
        "len(tokens)"
      ],
      "metadata": {
        "id": "Od3fnaoH_9aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "92q1DUJ3BJQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = list(set([token.lower() for token in tokens if token not in stop_words]))\n",
        "len(vocabulary)"
      ],
      "metadata": {
        "id": "yq7fnZBgApT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "    def __init__(self, vocabulary):\n",
        "        self.vocabulary = vocabulary\n",
        "        self.stoi = {vocabulary[i]:i+1 for i in range(len(vocabulary))}\n",
        "        self.itos = [vocabulary[i] for i in range(len(vocabulary))]\n",
        "\n",
        "        self.stoi['[UNK]'] = 0\n",
        "        self.itos = ['[UNK]'] + self.itos\n",
        "\n",
        "    def vocab_size(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    def __getitem__(self, key: str):\n",
        "        if key in self.stoi:\n",
        "            return self.stoi[key]\n",
        "\n",
        "        return self.stoi['[UNK]']\n",
        "\n",
        "    def decode(self, index:int):\n",
        "        if index in self.itos:\n",
        "            return self.itos[index]\n",
        "        return self.itos[0]"
      ],
      "metadata": {
        "id": "WhcmV7_oB4QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Vocab(vocabulary)\n",
        "len(vocabulary), len(vocab.itos), len(vocab.stoi.keys())"
      ],
      "metadata": {
        "id": "BuvXHSy1IfzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_lexicals = {}\n",
        "\n",
        "for split in ['train', 'validation']:\n",
        "    X_lexicals[split] = []\n",
        "    for i in tqdm(range(len(dataset[split]))):\n",
        "        bows = []\n",
        "\n",
        "        for si in [1,2]:\n",
        "            bow = [0 for i in range(vocab.vocab_size())]\n",
        "\n",
        "            for word in dataset[split][i][f'words{si}']:\n",
        "                word = word.lower()\n",
        "\n",
        "                idx = vocab[word]\n",
        "\n",
        "                bow[idx] +=1\n",
        "\n",
        "            bow = np.array(bow)\n",
        "            bow =  bow/np.sum(bow)\n",
        "\n",
        "            bows.extend(bow.tolist())\n",
        "\n",
        "        X_lexicals[split].append(bows)\n"
      ],
      "metadata": {
        "id": "WvIliRyXCXGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(random_state=42, svd_solver='full')\n",
        "pca.fit(X_lexicals['train'])\n",
        "explained_in_top = np.cumsum(pca.explained_variance_ratio_)\n",
        "#print(pca.singular_values_)"
      ],
      "metadata": {
        "id": "GzsX9S1aRj0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(X_lexicals['train']).shape, np.array(X_lexicals['validation']).shape"
      ],
      "metadata": {
        "id": "VZVh3u34ZBxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pca.explained_variance_ratio_)"
      ],
      "metadata": {
        "id": "Nzf_ZZUeYrGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "plt.ylim(0.0,1.1)\n",
        "\n",
        "\n",
        "xi = np.arange(0, len(explained_in_top), step=1)\n",
        "plt.plot(xi, explained_in_top, marker='o', linestyle='--', color='b')\n",
        "\n",
        "plt.xlabel('Number of Components')\n",
        "plt.xticks(np.arange(0, len(explained_in_top), step=50))\n",
        "plt.ylabel('Cumulative variance (%)')\n",
        "plt.title('The number of components needed to explain variance')\n",
        "\n",
        "plt.axhline(y=0.95, color='r', linestyle='-')\n",
        "plt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n",
        "\n",
        "ax.grid(axis='x')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zs_zoOHVYYIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_components = len(explained_in_top) - len(explained_in_top[explained_in_top>0.95])\n",
        "num_components"
      ],
      "metadata": {
        "id": "LMriPOuWRq8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_lexicals['train'] = pca.transform(X_lexicals['train'])[:,:num_components]\n",
        "X_lexicals['validation'] = pca.transform(X_lexicals['validation'])[:,:num_components]\n",
        "print(X_lexicals['train'].shape, X_lexicals['validation'].shape)"
      ],
      "metadata": {
        "id": "w4tQxRRsay38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classifier"
      ],
      "metadata": {
        "id": "qWDR4fC_czoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "# Classifier - Algorithm - SVM\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=1.0, kernel='poly', degree=3)\n",
        "\n",
        "\n",
        "X_train = X_lexicals['train']\n",
        "y_train = X['train']['target']\n",
        "\n",
        "\n",
        "SVM.fit(X_train, y_train)\n",
        "\n",
        "pred_train = SVM.predict(X_train)\n",
        "\n",
        "cm = confusion_matrix(y_train, pred_train)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=SVM.classes_)\n",
        "\n",
        "disp.plot()\n",
        "\n",
        "print(classification_report(y_pred=pred_train, y_true=y_train))"
      ],
      "metadata": {
        "id": "xiBFAkGMczQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pred_test)"
      ],
      "metadata": {
        "id": "NMDe0_HRdm7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = X_lexicals['validation']\n",
        "y_test = X['validation']['target']\n",
        "\n",
        "pred_test = SVM.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, pred_test)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=SVM.classes_)\n",
        "\n",
        "disp.plot()\n",
        "\n",
        "print(classification_report(y_pred=pred_test, y_true=y_test))"
      ],
      "metadata": {
        "id": "UsHQyuk5dN10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag of synsets"
      ],
      "metadata": {
        "id": "oiSoHWXSig2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "R1GEXsONi2oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "\n",
        "pos_map = {\n",
        "    'ADJ': ['a', 's'],\n",
        "    'NOUN': ['n'],\n",
        "    'VERB':  ['v'],\n",
        "    'ADV': ['r'],\n",
        "    'PROPN':['n']\n",
        "}\n",
        "from tqdm import tqdm\n",
        "\n",
        "def add_synset(example):\n",
        "    synsets = {}\n",
        "\n",
        "    for si in [1,2]:\n",
        "        synsets[si] = {}\n",
        "\n",
        "        for i in range(len(example[f'pos{si}'])):\n",
        "            pt = example[f'pos{si}'][i]\n",
        "            if pt not in pos_map:\n",
        "                continue\n",
        "\n",
        "            word = example[f'words{si}'][i]\n",
        "            for wn_pt in pos_map[pt]:\n",
        "                for word_synset in wn.synsets(word, pos=wn_pt):\n",
        "                    if word_synset.name() not in synsets:\n",
        "                        synsets[si][word_synset.name()] = 0\n",
        "                    synsets[si][word_synset.name()] +=1\n",
        "    return synsets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_synset(dataset_split):\n",
        "    synsets = []\n",
        "    for example in tqdm(dataset_split):\n",
        "        example_syns = add_synset(example)\n",
        "        concat_syns = {f'{si}-{synname}': example_syns[si][synname]\n",
        "                       for si in [1,2] for synname in example_syns[si]}\n",
        "\n",
        "        synsets.append(concat_syns)\n",
        "    return synsets\n",
        "\n",
        "\n",
        "\n",
        "X_synsets = {}\n",
        "\n",
        "for split in ['train', 'validation']:\n",
        "    X_synsets[split] = create_synset(dataset[split])"
      ],
      "metadata": {
        "id": "J-d9uk0ijitz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "v = DictVectorizer(sparse=False)\n",
        "v.fit(X_synsets['train'])\n",
        "\n",
        "for split in ['train', 'validation']:\n",
        "    X_synsets[split] = v.transform(X_synsets[split])\n",
        "\n",
        "    row_sums = X_synsets[split].sum(axis=1)\n",
        "\n",
        "    X_synsets[split] = X_synsets[split]/ row_sums[:, np.newaxis]"
      ],
      "metadata": {
        "id": "UIHaipG7u4ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(random_state=42, svd_solver='full')\n",
        "pca.fit(X_synsets['train'])\n",
        "explained_in_top = np.cumsum(pca.explained_variance_ratio_)\n",
        "#print(pca.singular_values_)"
      ],
      "metadata": {
        "id": "CHtOGhMsvBg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_components = len(explained_in_top) - len(explained_in_top[explained_in_top>0.95])\n",
        "\n",
        "X_synsets['train'] = pca.transform(X_synsets['train'])[:,:num_components]\n",
        "X_synsets['validation'] = pca.transform(X_synsets['validation'])[:,:num_components]\n",
        "print(X_synsets['train'].shape, X_synsets['validation'].shape)"
      ],
      "metadata": {
        "id": "bQu40bVdvLq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classifier"
      ],
      "metadata": {
        "id": "8DN_M7euvZKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "# Classifier - Algorithm - SVM\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=1.0, kernel='poly', degree=3)\n",
        "\n",
        "\n",
        "X_train = X_synsets['train']\n",
        "y_train = X['train']['target']\n",
        "\n",
        "\n",
        "SVM.fit(X_train, y_train)\n",
        "\n",
        "pred_train = SVM.predict(X_train)\n",
        "\n",
        "cm = confusion_matrix(y_train, pred_train)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=SVM.classes_)\n",
        "\n",
        "disp.plot()\n",
        "\n",
        "print(classification_report(y_pred=pred_train, y_true=y_train))"
      ],
      "metadata": {
        "id": "H9_xRWV4vSoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = X_synsets['validation']\n",
        "y_test = X['validation']['target']\n",
        "\n",
        "pred_test = SVM.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, pred_test)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=SVM.classes_)\n",
        "\n",
        "disp.plot()\n",
        "\n",
        "print(classification_report(y_pred=pred_test, y_true=y_test))"
      ],
      "metadata": {
        "id": "gGmf6KemvWVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Syntactically-filtered semantic features"
      ],
      "metadata": {
        "id": "xCFCk40qrc07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 1) words in the same role in the different sentences have have the similar synset\n",
        "### 2) Do predicates have the same synset? Is their meaning at least similar?\n",
        "########## Is \"included\" in the previous ones, that is, root word are similar\n",
        "### 3) Swap subjs and objs specific for active and passive forms"
      ],
      "metadata": {
        "id": "WBe_CCwprb4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_deps = {}\n",
        "\n",
        "for example in dataset['train']:\n",
        "    for si in [1,2]:\n",
        "        for dep in example[f'deprel{si}']:\n",
        "            if dep not in train_deps:\n",
        "                train_deps[dep] = 0\n",
        "            train_deps[dep]+=1\n",
        "\n",
        "sd = dict(sorted(train_deps.items(), key=lambda item: item[1]))\n",
        "fig =plt.figure(figsize=(20,10))\n",
        "plt.xticks(rotation = 45)\n",
        "plt.bar([k for k in sd], height=[sd[k] for k in sd], figure=fig)"
      ],
      "metadata": {
        "id": "FbUKNrbAs1mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0].keys()"
      ],
      "metadata": {
        "id": "uxEB4CUFXFqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_synsets(word, pt):\n",
        "    ss = set()\n",
        "\n",
        "    for wn_pt in pos_map[pt]:\n",
        "        for word_synset in wn.synsets(word, pos=wn_pt):\n",
        "                ss.add(word_synset)\n",
        "    return ss"
      ],
      "metadata": {
        "id": "RoI2BHSve5FS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_deprel = {}\n",
        "\n",
        "for split in ['train', 'validation']:\n",
        "    X_deprel[split] = []\n",
        "\n",
        "    for example in tqdm(dataset[split]):\n",
        "        rels_ex_features = {}\n",
        "        rels = set(example[f'deprel1']).intersection(set(example[f'deprel2'])) # find common rels\n",
        "\n",
        "        for rel in rels: # for each relation that is in common\n",
        "            indices = {si: [i for i, x in enumerate(example[f'deprel{si}']) if x == rel] for si in [1,2]} # find indices of words that have that relation\n",
        "\n",
        "            avg_sim = []\n",
        "            for i in indices[1]:\n",
        "                for j in indices[2]:\n",
        "                    #print(example['deprel1'])\n",
        "                    pos_tags = {1: example[\"pos1\"][i], 2:example[\"pos2\"][j]}\n",
        "                    #print(pos_tags)\n",
        "                    words = {1:example['words1'][i], 2: example['words2'][j]}\n",
        "                    #print(words)\n",
        "\n",
        "                    if pos_tags[1] in pos_map and pos_tags[2] in pos_map and pos_tags[1] == pos_tags[2]: # if it is a content word\n",
        "                        # collect all synsets\n",
        "                        synsets = {}\n",
        "                        for si in [1,2]:\n",
        "                            synsets[si] = get_all_synsets(words[si], pos_tags[si])\n",
        "\n",
        "                        if len(synsets[1]) != 0 and len(synsets[2]) != 0:\n",
        "                            for s1 in synsets[1]:\n",
        "                                for s2 in synsets[2]:\n",
        "                                    avg_sim.append(wn.wup_similarity(s1, s2))\n",
        "                        else:\n",
        "                            avg_sim.append(0)\n",
        "\n",
        "\n",
        "            #print(rel, indices)\n",
        "            if len(avg_sim) != 0:\n",
        "                avg_sim = max(avg_sim)\n",
        "                rels_ex_features[rel] = avg_sim\n",
        "\n",
        "        X_deprel[split].append(rels_ex_features)"
      ],
      "metadata": {
        "id": "xd1G0S_T0AOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "v = DictVectorizer(sparse=False)\n",
        "v.fit(X_deprel['train'])\n",
        "X_deprel2 = {}\n",
        "for split in ['train', 'validation']:\n",
        "    X_deprel2[split] = v.transform(X_deprel[split])"
      ],
      "metadata": {
        "id": "wdVG9JpPfvfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classifier"
      ],
      "metadata": {
        "id": "VpA_C1sdhMrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "# Classifier - Algorithm - SVM\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=1.0, kernel='poly', degree=3)\n",
        "\n",
        "\n",
        "X_train = X_deprel2['train']\n",
        "y_train = X['train']['target']\n",
        "\n",
        "\n",
        "SVM.fit(X_train, y_train)\n",
        "\n",
        "pred_train = SVM.predict(X_train)\n",
        "\n",
        "cm = confusion_matrix(y_train, pred_train)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=SVM.classes_)\n",
        "\n",
        "disp.plot()\n",
        "\n",
        "print(classification_report(y_pred=pred_train, y_true=y_train))"
      ],
      "metadata": {
        "id": "-LoFoTB-gDCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = X_deprel2['validation']\n",
        "y_test = X['validation']['target']\n",
        "\n",
        "pred_test = SVM.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, pred_test)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=SVM.classes_)\n",
        "\n",
        "disp.plot()\n",
        "\n",
        "print(classification_report(y_pred=pred_test, y_true=y_test))"
      ],
      "metadata": {
        "id": "lI_gf_QsgICB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0mHSQRm1NYIb",
        "LIzic0LwNdGT"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNEWOsJxXgJ1CUShtI3RlU0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3902e0a182f34b1d89dc789d6cf35494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d5a5ed8bd4e46caa18682ea63eb86bc",
              "IPY_MODEL_634052a393ef4e9395986daeb365a1c8",
              "IPY_MODEL_f156f93c71454009be44f43dc4769aa5"
            ],
            "layout": "IPY_MODEL_427f2c4c077c4147a0e96cff3d702155"
          }
        },
        "5d5a5ed8bd4e46caa18682ea63eb86bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ec7f972593e47cabf4b84e94277384f",
            "placeholder": "​",
            "style": "IPY_MODEL_12bed84d704a47ce84d648c89d9b4305",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.7.0.json: "
          }
        },
        "634052a393ef4e9395986daeb365a1c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce182cc2bdeb45e78a083326ce90856f",
            "max": 46172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_855a54b30b414e3d9d828e0f5338582c",
            "value": 46172
          }
        },
        "f156f93c71454009be44f43dc4769aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f975a4a6a5e46b3b7af3cedce22fb85",
            "placeholder": "​",
            "style": "IPY_MODEL_959b7696f6774e46b05bf6a4dfd2d33b",
            "value": " 370k/? [00:00&lt;00:00, 5.09MB/s]"
          }
        },
        "427f2c4c077c4147a0e96cff3d702155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ec7f972593e47cabf4b84e94277384f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12bed84d704a47ce84d648c89d9b4305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce182cc2bdeb45e78a083326ce90856f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "855a54b30b414e3d9d828e0f5338582c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f975a4a6a5e46b3b7af3cedce22fb85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "959b7696f6774e46b05bf6a4dfd2d33b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f78af7a52f5347a6b15ceabb4d57a519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4a663d0a4b34f9b9173bfe58397d5b1",
              "IPY_MODEL_26e79a77e88c4a1c8a1b1352908e9f74",
              "IPY_MODEL_b397e0a871e54c85921a5c93fe16aa7c"
            ],
            "layout": "IPY_MODEL_bedd51e2ed524f5fad8fd747682613c5"
          }
        },
        "b4a663d0a4b34f9b9173bfe58397d5b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d31fd54f8733440aaab0cc751de96c34",
            "placeholder": "​",
            "style": "IPY_MODEL_ab3282e9c1854e73ae818bbd169ddf33",
            "value": "Map:  13%"
          }
        },
        "26e79a77e88c4a1c8a1b1352908e9f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0c137bae7b64c68996f239ecd86a7ac",
            "max": 1467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_479ad2b4ce044a7da9e91d33952abf25",
            "value": 188
          }
        },
        "b397e0a871e54c85921a5c93fe16aa7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f3ed4402e164550aafeacfb4241a176",
            "placeholder": "​",
            "style": "IPY_MODEL_9c216a48cbdc432fa9b113c3e4a4691e",
            "value": " 188/1467 [04:32&lt;49:51,  2.34s/ examples]"
          }
        },
        "bedd51e2ed524f5fad8fd747682613c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d31fd54f8733440aaab0cc751de96c34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab3282e9c1854e73ae818bbd169ddf33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0c137bae7b64c68996f239ecd86a7ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "479ad2b4ce044a7da9e91d33952abf25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f3ed4402e164550aafeacfb4241a176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c216a48cbdc432fa9b113c3e4a4691e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}